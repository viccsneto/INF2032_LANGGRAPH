{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e5700d",
   "metadata": {},
   "source": [
    "### **Before you run this make sure you have the OPENAI_API_KEY and TAVILY_API_KEY environment variables declared**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268e5e",
   "metadata": {},
   "source": [
    "### 1 Define the tool\n",
    "\n",
    "Define the web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c38552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40b180",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b4938",
   "metadata": {},
   "source": [
    "### 2 Define the graph\n",
    "For the `StateGraph` you created in the first tutorial, add `bind_tools` on the LLM. This lets the LLM know the correct JSON format to use if it wants to use the search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297798f8",
   "metadata": {},
   "source": [
    "Let's first select our LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95797e42",
   "metadata": {},
   "source": [
    " We can now incorporate it into a `StateGraph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "# highlight-next-line\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dae6f",
   "metadata": {},
   "source": [
    "### 3 Create a function to run the tools\n",
    "Now, create a function to run the tools if they are called. Do this by adding the tools to a new node called `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls`. It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1831f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee74a6",
   "metadata": {},
   "source": [
    "### 4 Define the `conditional_edges`\n",
    "With the tool node added, now you can define the conditional_edges.\n",
    "\n",
    "**Edges** route the control flow from one node to the next. **Conditional edges** start from a single node and usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph `state` and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Next, define a router function called `route_tools` that checks for `tool_calls` in the chatbot's output. Provide this function to the graph by calling `add_conditional_edges`, which tells the graph that whenever the `chatbot` node completes to check this function to see where to go next.\n",
    "\n",
    "The condition will route to `tools` if tool calls are present and `END` if not. Because the condition can return `END`, you do not need to explicitly set a finish_point this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f400783",
   "metadata": {},
   "source": [
    "### 5 Visualize the graph\n",
    "You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The draw methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b335660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103afdc",
   "metadata": {},
   "source": [
    "### 6 Ask the bot questions\n",
    "Now you can ask the chatbot questions outside its training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bebe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0701d3",
   "metadata": {},
   "source": [
    "### Add Memory\n",
    "The chatbot can now use tools to answer user questions, but it does not remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "LangGraph solves this problem through **persistent checkpointing**. If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off.\n",
    "\n",
    "We will see later that **checkpointing** is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But first, let's add checkpointing to enable multi-turn conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2c305",
   "metadata": {},
   "source": [
    "### 1 Create a `MemorySaver` checkpointer\n",
    "Create a `MemorySaver` checkpointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08be87",
   "metadata": {},
   "source": [
    "This is in-memory checkpointer, which is convenient for the tutorial. However, in a production application, you would likely change this to use `SqliteSaver` or `PostgresSaver` and connect a database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697206d",
   "metadata": {},
   "source": [
    "### 2. Compile the graph\n",
    "Compile the graph with the provided checkpointer, which will checkpoint the `State` as the graph works through each node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af781c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0edde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be379e36",
   "metadata": {},
   "source": [
    "### 3 Interact with your chatbot\n",
    "\n",
    "Now you can interact with your bot!\n",
    "\n",
    "1. Pick a thread to use as the key for this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93992f",
   "metadata": {},
   "source": [
    "2. Call your chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184b4a0",
   "metadata": {},
   "source": [
    "### 4 Ask a follow up question\n",
    "Ask a follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ab706",
   "metadata": {},
   "source": [
    "**Notice** that we aren't using an external list for memory: it's all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what's going on.\n",
    "\n",
    "Don't believe me? Try this using a different config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b414ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d0095",
   "metadata": {},
   "source": [
    "**Notice** that the **only** change we've made is to modify the `thread_id` in the config."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557840c",
   "metadata": {},
   "source": [
    "### 5 Inpect the state\n",
    "By now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph's `state` for a given config at any time, call `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a574011",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f2306",
   "metadata": {},
   "source": [
    "The snapshot above contains the current state values, corresponding config, and the `next` node to process. In our case, the graph has reached an `END` state, so `next` is empty.\n",
    "\n",
    "**Congratulations**! Your chatbot can now maintain conversation state across sessions thanks to LangGraph's checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph's checkpointing even handles **arbitrarily complex graph states**, which is much more expressive and powerful than simple chat memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e793c",
   "metadata": {},
   "source": [
    "### Add human-in-the-loop controls\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "LangGraph's persistence layer supports **human-in-the-loop** workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the `interrupt` function. Calling `interrupt` inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. `interrupt` is ergonomically similar to Python's built-in input(), with some caveats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff10269",
   "metadata": {},
   "source": [
    "### 1 Add the `human_assistance` tool\n",
    "Starting with the existing code from the Add memory to the chatbot tutorial, add the `human_assistance` tool to the chatbot. This tool uses `interrupt` to receive information from a human.\n",
    "\n",
    "Let's first select a chat model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c407b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de29fa",
   "metadata": {},
   "source": [
    "We can now incorporate it into our `StateGraph` with an additional tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b1d9a",
   "metadata": {},
   "source": [
    "### 2 Compile the graph\n",
    "We compile the graph with a checkpointer, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053e703",
   "metadata": {},
   "source": [
    "### 3. Visualize the graph\n",
    "Visualizing the graph, you get the same layout as before – just with the added tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223f641",
   "metadata": {},
   "source": [
    "### 4 Prompt the chatbot\n",
    "Now, prompt the chatbot with a question that will engage the new `human_assistance` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89052839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d9b60",
   "metadata": {},
   "source": [
    "The chatbot generated a tool call, but then execution has been interrupted. If you inspect the graph state, you see that it stopped at the tools node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78d29a",
   "metadata": {},
   "source": [
    "### 5 Resume execution\n",
    "To resume execution, pass a `Command` object containing data expected by the tool. The format of this data can be customized based on needs. For this example, use a dict with a key `\"data\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf272b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb03315",
   "metadata": {},
   "source": [
    "The input has been received and processed as a tool message. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\n",
    "\n",
    "**Congratulations!** You've used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since you have already added a **checkpointer**, as long as the underlying persistence layer is running, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d82ef1",
   "metadata": {},
   "source": [
    "### Customize State\n",
    "In this tutorial, you will add additional fields to the state to define complex behavior without relying on the message list. The chatbot will use its search tool to find specific information and forward them to a human for review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10b3e6",
   "metadata": {},
   "source": [
    "### 1 Add keys to the state\n",
    "Update the chatbot to research the birthday of an entity by adding `name` and `birthday` keys to the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2377d",
   "metadata": {},
   "source": [
    "Adding this information to the state makes it easily accessible by other graph nodes (like a downstream node that stores or processes the information), as well as the graph's persistence layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eefdfd",
   "metadata": {},
   "source": [
    "### 2. Update the state inside the tool\n",
    "Now, populate the state keys inside of the `human_assistance` tool. This allows a human to review the information before it is stored in the state. Use `Command` to issue a state update from inside the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is declared before\n",
    "\"\"\" \n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215cc70",
   "metadata": {},
   "source": [
    "The rest of the graph stays the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22faa830",
   "metadata": {},
   "source": [
    "### 3. Prompt the chatbot\n",
    "Prompt the chatbot to look up the \"birthday\" of the LangGraph library and direct the chatbot to reach out to the `human_assistance` tool once it has the required information. By setting `name` and `birthday` in the arguments for the tool, you force the chatbot to generate proposals for these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5eeec",
   "metadata": {},
   "source": [
    "We've hit the interrupt in the `human_assistance` tool again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d055688",
   "metadata": {},
   "source": [
    "### 4. Add human assistance¶\n",
    "The chatbot failed to identify the correct date, so supply it with information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a1795",
   "metadata": {},
   "source": [
    "Note that these fields are now reflected in the state (NOT REALLY):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae7801",
   "metadata": {},
   "source": [
    "**Note**: It should not be empty, but has the following information {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa164e",
   "metadata": {},
   "source": [
    "### 5. Manually update the state\n",
    "LangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), you can manually override a key using `graph.update_state`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5486f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ad775",
   "metadata": {},
   "source": [
    "### 6 View the new value\n",
    "If you call `graph.get_state`, you can see the new value is reflected (NOT REALLY):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db79f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.values.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d6320",
   "metadata": {},
   "source": [
    "Manual state updates will generate a trace in LangSmith. If desired, they can also be used to control human-in-the-loop workflows. Use of the `interrupt` function is generally recommended instead, as it allows data to be transmitted in a human-in-the-loop interaction independently of state updates.\n",
    "\n",
    "**Congratulations!** You've added custom keys to the state to facilitate a more complex workflow, and learned how to generate state updates from inside tools.\n",
    "\n",
    "Check out the code snippet below to review the graph from this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91128cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "@tool\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225d87e",
   "metadata": {},
   "source": [
    "### Time travel\n",
    "#### RESUME_TUTORIAL\n",
    "\n",
    "In a typical chatbot workflow, the user interacts with the bot one or more times to accomplish a task. Memory and a human-in-the-loop enable checkpoints in the graph state and control future responses.\n",
    "\n",
    "What if you want a user to be able to start from a previous response and explore a different outcome? Or what if you want users to be able to rewind your chatbot's work to fix mistakes or try a different strategy, something that is common in applications like autonomous software engineers?\n",
    "\n",
    "You can create these types of experiences using LangGraph's built-in **time travel** functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd8a51",
   "metadata": {},
   "source": [
    "### 1 Rewind your graph\n",
    "\n",
    "Rewind your graph by fetching a checkpoint using the graph's `get_state_history` method.\n",
    "You can then resume execution at this previous point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bc12bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "492887fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441eafed",
   "metadata": {},
   "source": [
    "### 2 Add steps\n",
    "Add steps to your graph. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ebb6d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_6GqcF9U9uf2xCrwiGD8ZChtf)\n",
      " Call ID: call_6GqcF9U9uf2xCrwiGD8ZChtf\n",
      "  Args:\n",
      "    query: LangGraph overview, use cases, and documentation\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph overview, use cases, and documentation\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.\", \"score\": 0.78014404, \"raw_content\": null}, {\"title\": \"LangGraph Platform\", \"url\": \"https://www.langchain.com/langgraph-platform\", \"content\": \"LangGraph Platform [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)[LangSmith](https://docs.smith.langchain.com/)[LangChain](https://python.langchain.com/docs/introduction/) [LangGraph](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/)[LangSmith](https://docs.smith.langchain.com/)[LangChain](https://js.langchain.com/docs/introduction/) Develop, deploy, and scale agents with LangGraph Platform — our purpose-built platform for long-running, stateful workflows. [Get a demo](/contact-sales)[See the docs](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) [See our deployment options](https://langchain-ai.github.io/langgraph/concepts/deployment_options/) ![](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/681d8ccac0cebd9db8bee444_Accelerate%20agent%20develop%20(compressed).gif) [Try out LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/) [Modify agents with Assistants](https://langchain-ai.github.io/langgraph/concepts/assistants/) ![](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/681d8cda22c17ba7d6835349_Centralized-agent-management_v3.gif) No. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio. LangGraph Platform What are my deployment options for LangGraph Platform? ## Resources for LangGraph Platform ### What is LangGraph Platform Video](https://www.youtube.com/watch?v=pfAQxBS5z88)[![ ](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c63f169b489597c789d635_resources-bg-2.jpg) ### LangGraph Platform Deployment Options](https://langchain-ai.github.io/langgraph/concepts/deployment_options/)[![](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c63f16e69c3fb010a9a2a8_resources-bg-3.jpg) ### LangGraph Platform Docs Overview](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) [LangChain](/langchain)[LangSmith](/langsmith)[LangGraph](/langgraph)[Agents](/agents)[Evaluation](/evaluation)[Retrieval](/retrieval) [Python Docs](https://python.langchain.com/)[JS/TS Docs](https://js.langchain.com/docs/get_started/introduction/)[GitHub](https://github.com/langchain-ai)[Integrations](https://python.langchain.com/docs/integrations/providers/)[Changelog](https://changelog.langchain.com/)[Community](/join-community)[LangSmith Trust Portal](https://trust.langchain.com/)\", \"score\": 0.7339103, \"raw_content\": null}], \"response_time\": 2.04}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s an overview of LangGraph based on my research:\n",
      "\n",
      "- LangGraph is an open-source AI agent framework created by the makers of LangChain.\n",
      "- It is designed for building, deploying, and managing complex generative AI agent workflows, such as chatbots, state graphs, and other agent-based systems.\n",
      "- LangGraph uses graph-based architectures, where nodes represent components or agents in the workflow. These nodes can analyze their actions and feedback, allowing for advanced decision-making and transparency.\n",
      "- The framework is well-suited for long-running, stateful workflows and offers more low-level control than LangChain’s standard agent framework.\n",
      "- LangGraph Platform: This is an associated service for deploying and scaling LangGraph applications, providing APIs, agent management, and an integrated developer studio for building agent user experiences.\n",
      "\n",
      "Resources:\n",
      "- Official docs: LangGraph Platform Docs Overview\n",
      "- Quickstart and tutorials: LangGraph Tutorials\n",
      "- Deployment options and advanced guides are also available.\n",
      "\n",
      "If you need more specific information such as sample code, best practices, or a deep dive into its architecture, let me know!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1187a818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great idea! LangGraph is well-suited for building autonomous agents, especially if you want your agent to have sophisticated, stateful, or multi-step decision-making logic. Here’s how it can help:\n",
      "\n",
      "- You can model each component or capability of your agent as a node in the graph.\n",
      "- LangGraph makes it easier to manage complex flows, handle agent memory/state, and debug or visualize decisions.\n",
      "- Its integration with LangChain means you can leverage many tools and large language models easily.\n",
      "\n",
      "If you want to get started, here are some next steps:\n",
      "- Check out the LangGraph Quickstart Tutorial for hands-on guidance.\n",
      "- Review example projects or templates (if you want, I can look some up).\n",
      "- Map out the high-level abilities and behaviors your autonomous agent should have, and model these as LangGraph nodes.\n",
      "\n",
      "Let me know if you’d like sample code, learning resources, agent design tips, or anything else as you start your project!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d840aa6",
   "metadata": {},
   "source": [
    "### 3 Replay the full state history\n",
    "Now that you have added steps to the chatbot, you can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "885804d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a783769",
   "metadata": {},
   "source": [
    "Checkpoints are saved for every step of the graph. This **spans invocations** so you can rewind across a full thread's history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de96b9a",
   "metadata": {},
   "source": [
    "### Resume from a checkpoint\n",
    "Resume from the `to_replay` state, which is after the chatbot node in the second graph invocation. Resuming from this point will call the *action* node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "83e9af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f036370-215f-63ba-8006-a12b05d02bf6'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c525a7f",
   "metadata": {},
   "source": [
    "### The output should be something like this\n",
    "```\n",
    "('tools',)\n",
    "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd43e3-0c1f-6c4e-8006-891877d65740'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5fd8d5",
   "metadata": {},
   "source": [
    "### 4 Load a state from a moment-in-time\n",
    "The checkpoint's to_replay.config contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8b5e4370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great idea! LangGraph is well-suited for building autonomous agents, especially if you want your agent to have sophisticated, stateful, or multi-step decision-making logic. Here’s how it can help:\n",
      "\n",
      "- You can model each component or capability of your agent as a node in the graph.\n",
      "- LangGraph makes it easier to manage complex flows, handle agent memory/state, and debug or visualize decisions.\n",
      "- Its integration with LangChain means you can leverage many tools and large language models easily.\n",
      "\n",
      "If you want to get started, here are some next steps:\n",
      "- Check out the LangGraph Quickstart Tutorial for hands-on guidance.\n",
      "- Review example projects or templates (if you want, I can look some up).\n",
      "- Map out the high-level abilities and behaviors your autonomous agent should have, and model these as LangGraph nodes.\n",
      "\n",
      "Let me know if you’d like sample code, learning resources, agent design tips, or anything else as you start your project!\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
