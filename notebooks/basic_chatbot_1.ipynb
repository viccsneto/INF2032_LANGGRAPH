{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56268e5e",
   "metadata": {},
   "source": [
    "### 1 Create a StateGraph\n",
    "#### Now you can create a basic chatbot using LangGraph. This chatbot will respond directly to user messages.\n",
    "\n",
    "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c38552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40b180",
   "metadata": {},
   "source": [
    "### Our graph can now handle two key tasks:\n",
    "\n",
    "1. Each `node` can receive the current `State` as input and output an update to the state.\n",
    "2. Updates to `messages` will be appended to the existing list rather than overwriting it, thanks to the prebuilt `add_messages` function used with the Annotated syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b4938",
   "metadata": {},
   "source": [
    "### 2 Add a node\n",
    "Next, add a \"chatbot\" node. Nodes represent units of work and are typically regular Python functions.\n",
    "\n",
    "Let's first select a chat model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95797e42",
   "metadata": {},
   "source": [
    " We can now incorporate the chat model into a simple node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21546f01",
   "metadata": {},
   "source": [
    "**Notice** how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The `add_messages` function in our State will append the LLM's response messages to whatever messages are already in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dae6f",
   "metadata": {},
   "source": [
    "### 3 Add an entry point\n",
    "Add an `entry` point to tell the graph **where to start its work** each time it is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1831f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee74a6",
   "metadata": {},
   "source": [
    "### 4 Compile the graph\n",
    "Before running the graph, we'll need to compile it. We can do so by calling `compile()` on the graph builder. This creates a `CompiledGraph` we can invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f400783",
   "metadata": {},
   "source": [
    "### 5 Visualize the graph\n",
    "You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The draw methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b335660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103afdc",
   "metadata": {},
   "source": [
    "### 6 Run the chatbot\n",
    "Now run the chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bebe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
